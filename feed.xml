<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:dc="http://purl.org/dc/elements/1.1/">
	<channel>
		<title>Journey through image and programming</title>
		<description>My personal blog, serve as a demo</description>
		<link>http://localhost:4000</link>
		<atom:link href="http://localhost:4000/feed.xml" rel="self" type="application/rss+xml" />
		
			<item>
				<title>Simple Facial Rigging and Walk Cycle Demo</title>
				
				
					<description>&lt;p&gt;I did a quick facial animation and walk cycle with Maya and Renderman.
&lt;br /&gt;&lt;br /&gt;
Facial rigging is done with my own script and the walk cycle is used to demonstrate different layers within this character.&lt;/p&gt;
</description>
				
				<pubDate>Wed, 31 Jan 2018 00:00:00 -0800</pubDate>
				<link>http://localhost:4000/post/walk-demo/</link>
				<guid isPermaLink="true">http://localhost:4000/post/walk-demo/</guid>
			</item>
		
			<item>
				<title>Convert any photo to seamless texture</title>
				
				
					<description>&lt;h1 id=&quot;overview&quot;&gt;&lt;strong&gt;Overview:&lt;/strong&gt;&lt;/h1&gt;
&lt;p&gt;I wrote a script that run in mayapy. It can convert photos into seamless tile. The quality of the result will obviously depended on the original image. Some images are just not made for seamless texture. The program itself is using a algorithm, minimal error boundary. The algorithm is a variation of another more famous algorithm called, seam curving. Seam curving is covered in most university level computer vision programming classes. It is almost a rite of passage for any programmer in the field of graphic or image editing. And because the algorithm uses dynamic programming. some advance programming courses will also use it as assignment or project.
&lt;br /&gt;&lt;br /&gt;
&lt;img src=&quot;/img/seamless_script/ui.jpg&quot; alt=&quot;eamless_script UI&quot; class=&quot;center-image&quot; /&gt;
&lt;br /&gt;&lt;br /&gt;&lt;/p&gt;
&lt;h1 id=&quot;what-is-seamless-texture&quot;&gt;&lt;strong&gt;What is Seamless texture?&lt;/strong&gt;&lt;/h1&gt;
&lt;p&gt;Seamless image, basically means the left side of the image matches the right side of the image. Same with the top and bottom side. This is useful because in a modeler may want to cover a large geometry with the same repeating textures.
&lt;br /&gt;&lt;br /&gt;
&lt;img src=&quot;/img/seamless_script/leave_tile_expl.jpg&quot; alt=&quot;leave_tile&quot; class=&quot;center-image&quot; /&gt;
&lt;br /&gt;&lt;br /&gt;&lt;/p&gt;
&lt;h1 id=&quot;my-method&quot;&gt;&lt;strong&gt;My method:&lt;/strong&gt;&lt;/h1&gt;
&lt;p&gt;As the picture shown, the trick is overlapping the left and right part of the image. And to find the best seam to combine the image I am using the algorithm I mentioned above. To understand the algorithm I include this link for more detail.
&lt;br /&gt;
To make the image both vertical and horizontal seamless, I rotate the image and ran the same process again.
&lt;br /&gt;
Also, I included a check box in my UI to center the image. What it means is that do I preserve the original center of the original image. As you can see, the way I merge my image will split the center of the original image. In some case, user may still want to persevere center, so I offered the option to center it.
&lt;br /&gt;&lt;br /&gt;
&lt;img src=&quot;/img/seamless_script/method.jpg&quot; alt=&quot;method explain&quot; class=&quot;center-image&quot; /&gt;
&lt;br /&gt;&lt;br /&gt;
Operation Demo:
&lt;a href=&quot;http://&quot;&gt;link to video&lt;/a&gt;&lt;/p&gt;
</description>
				
				<pubDate>Wed, 31 Jan 2018 00:00:00 -0800</pubDate>
				<link>http://localhost:4000/post/sealmess-tex-script/</link>
				<guid isPermaLink="true">http://localhost:4000/post/sealmess-tex-script/</guid>
			</item>
		
			<item>
				<title>Throughts on using geometry as light in Renderman 21</title>
				
				
					<description>&lt;p&gt;In Renderman 21, when people need a self illumination geometry, for example a light bulb filament or a Neon light tube, there are usually 2 way to do that. One is adding value to ‘Grow’ attribute in a standard ‘PxrSurface’. Two is using ‘Pxrblack’, treating the geometry as black body object emitting light.
&lt;br /&gt;&lt;br /&gt;
The problem with that statement is that the ‘Grow’ lighting method is not really a lighting method. It lack basic lighting attribute, like intensity or exporsure. So I went on and did some experiments on my own. What I found is that, ‘Grow’ attribute is just a ‘PxrConstant’ shader. 
&lt;br /&gt;&lt;br /&gt;&lt;/p&gt;
&lt;center&gt;PxrSurface,  Grow_gain = 1.0&lt;/center&gt;
&lt;p&gt;&lt;img src=&quot;/img/renm_geo_light/pxrfur_g.jpg&quot; alt=&quot;PxrSurface,  Grow_gain = 1.0&quot; class=&quot;center-image&quot; /&gt;
&lt;br /&gt;&lt;br /&gt;&lt;/p&gt;
&lt;center&gt;PxrConstant, gain = 1.0&lt;/center&gt;
&lt;p&gt;&lt;img src=&quot;/img/renm_geo_light/pxrcons.jpg&quot; alt=&quot;PxrConstant, gain = 1.0&quot; class=&quot;center-image&quot; /&gt;
&lt;br /&gt;&lt;br /&gt;
As you can see, the PxrSurface grow gain and PxrConstant gain is practically the identical. The resulting image is virtually identical. What this proves is that, grow attribute actually don’t grow. It just treat the mesh as a non-reflective surface with a constant color, no matter the direction the render ray arrive. Another thing worth noticing, if one look carefully, the brick wall behind the neon light did light up slightly. Although, the reflection is very dime, it did appear to light up. The reason behind it is because color a pixel is the summation of reflection and refraction. If there are no light, the refraction value will be zero( but to be 100% correct, Renderman have small default global illumination ). But because of reflection, a pixel can still light up. The smooth part of the wall reflect the render ray and the render ray may hit the neon light on the second path or maybe the forth path. Hence, the wall will appear to be light up.
&lt;br /&gt;&lt;br /&gt;&lt;/p&gt;
&lt;center&gt;And now, lets compare the result with PxrBlackBody geometry:&lt;/center&gt;
&lt;p&gt;&lt;img src=&quot;/img/renm_geo_light/fin_light.jpg&quot; alt=&quot;PxrBlack as the only light source&amp;lt;&quot; class=&quot;center-image&quot; /&gt;
&lt;br /&gt;&lt;br /&gt;
The light from the black body light up the surrounding geometry, including the wall and the floor. As you can see, there is a clear reflection on the wall behind the neon light. More importantly, everything in the room is light up, which means refraction is hard at work.
&lt;br /&gt;&lt;br /&gt;
As a conclusion, there is only one way to using geometry as light, that is ‘PxrBlack’. Both ‘Grow’ and ‘constant color’ are the same way to fake a self-Illuminati. But this don’t mean ‘PxrBlack’ is the better shader, ‘PxrBlack’ will take significantly longer time to render. So if the geometry is not he only light source in the scene, the better choice may just be faking it.&lt;/p&gt;
</description>
				
				<pubDate>Wed, 31 Jan 2018 00:00:00 -0800</pubDate>
				<link>http://localhost:4000/post/renderman-geo-light/</link>
				<guid isPermaLink="true">http://localhost:4000/post/renderman-geo-light/</guid>
			</item>
		
			<item>
				<title>My Custom Module Architect Building Tool</title>
				
				
					<description>&lt;p&gt;I recently came across a Maya plugin: Ninja Dojo, ninja city (aka, Render ready Demo)
&lt;br /&gt;
&lt;a href=&quot;http://www.bk3d.com/Ninja_Dojo/&quot;&gt;Ninja Dojo&lt;/a&gt;
&lt;br /&gt;
&lt;a href=&quot;https://www.highend3d.com/maya/script/render-ready-demo-for-maya&quot;&gt;Render ready demo&lt;/a&gt;
&lt;br /&gt;&lt;br /&gt;
It is a very well written script, but unfortunately the author has stop updating it for newer Maya. Also there are limitations in the software that I dislike (mostly because I am using a different renderer), I prefer tools with more freedom. So I decide to write my own.
&lt;br /&gt;&lt;br /&gt;&lt;/p&gt;
&lt;center&gt;Finished UI&lt;/center&gt;
&lt;p&gt;&lt;img src=&quot;/img/modu_building/ui.jpg&quot; alt=&quot;UI display&quot; class=&quot;center-image&quot; /&gt;
&lt;br /&gt;&lt;br /&gt;
So on the left side I have the finished script UI. In principle, this script is basically just a duplicator. User can put a mesh or a mesh group name into the “object name” field in the top left side, which will link to the “Module Name” on the left side. And in the main table below, I can use these modules to one by one build the building.
&lt;br /&gt;&lt;br /&gt;
The reason I wrote it this way is because:
&lt;br /&gt;
One, I can link multiple objects to the same Module Name. So that, when the script duplicates the module, it will randomly choose one from the multiple objects. This is useful when, for example, user has several different window shadings and wants them to be placed at random positions. 
&lt;br /&gt;
Two, user may wants different meshes for the ground floor and top floor, but retaining the same basic patterns that established one story below. By linking the object and module this way, user don’t have to go into the “Modula Name” field and update each rows in the main table, which is usually much longer than the list above. 
&lt;br /&gt;
Also by doing it this way I am not importing object files every time I build a new module. Duplicating is not only faster, but also it wouldn’t trigger the student version import warning.
&lt;br /&gt;&lt;br /&gt;
This script’s UI is based on pyqt5, which is new for Maya 2017. The reason behind it is because it handles list/table objects better than other UIs I tried. The saving and loading is done by using JSON file format. This way is preferred because the result JSON file is human friendly. User can imminently open it as a text file and see the data just created. 
&lt;br /&gt;
But I have to admit, there is a down fall with this method. The saved data has a strong relation with mesh dimension. The saved JSON data can only correctly duplicate modules, if they use the same travel and offsets.
&lt;br /&gt;&lt;br /&gt;
Comparing with Ninja City, my script has less constraints. User have the choice to use any meshes or shaders they want to, no string attached. Functionally, I can place my module at any degree I want, let say 30 degree or 45 degree. Which is very hard to do in Ninja City. Also, I can change my design pattern midway on the building, for example, the base can be a 4x5 pattern. And everything above can be 3x3 pattern. Which in Ninja City I have to stack 2 buildings to achieve the same affect.
&lt;br /&gt;&lt;br /&gt;
And since this script was written within 1 day, I am happy to share it:
&lt;a href=&quot;http://&quot;&gt;Still working on it&lt;/a&gt;&lt;/p&gt;
</description>
				
				<pubDate>Wed, 31 Jan 2018 00:00:00 -0800</pubDate>
				<link>http://localhost:4000/post/modu-building/</link>
				<guid isPermaLink="true">http://localhost:4000/post/modu-building/</guid>
			</item>
		
			<item>
				<title>My Facial Animation Solution</title>
				
				
					<description>&lt;p&gt;After testing a few different facial animation methods in Maya, I settle down with my own method. 
&lt;br /&gt;The ideal is to combining curved based animation and blendshape based animation, utilizing custom python script to get the best of both worlds.
&lt;br /&gt;&lt;br /&gt;&lt;/p&gt;
&lt;center&gt;Gernel Oervew&lt;/center&gt;
&lt;p&gt;&lt;img src=&quot;/img/facial_anim/overview.PNG&quot; alt=&quot;overview&quot; class=&quot;center-image&quot; /&gt;
&lt;br /&gt;&lt;br /&gt;
Blendshape based facial animation is the most accurate and user-friendly way I found so far, but to perform a blendshape deform the machine have to check topology of all the blendshape copies, which preform-wise is very costly. 
&lt;br /&gt;Curved based deform is very light-weight, but user often don’t get the optimal result because different curve usually interfere with each other.
&lt;br /&gt;&lt;br /&gt;
As a result, I wrote my own method. First, I copied the face mesh using it as blendshape pipe. Second, I will create curves based on the model’s facial structure. Third, the curves were build based on joints, I would use these joints to skin my blendshape mesh. And at last, I will copy and blendshpe the curves and create a blendshape control, so that, I have use my copied curves to blendshape deform the curves on the copied mesh. And pipe all my deform into my original mesh.
&lt;br /&gt;&lt;br /&gt;&lt;/p&gt;
&lt;center&gt;Finished controls&lt;/center&gt;
&lt;p&gt;&lt;img src=&quot;/img/facial_anim/contorls.PNG&quot; alt=&quot;control handles&quot; class=&quot;center-image&quot; /&gt;
&lt;br /&gt;&lt;br /&gt;
 The whole idea is to use curves to replace blendshape mesh. And by doing blendshape blending on curves, we can accelerate the deformation calculation speed.&lt;/p&gt;
</description>
				
				<pubDate>Wed, 31 Jan 2018 00:00:00 -0800</pubDate>
				<link>http://localhost:4000/post/facial-anim/</link>
				<guid isPermaLink="true">http://localhost:4000/post/facial-anim/</guid>
			</item>
		
			<item>
				<title>My throughts on extrude along curve</title>
				
				
					<description>&lt;p&gt;Creating Stairs is one of the most tedious task in 3D modeling. There are a lot of repetition in the modeling and everything has been very precise. In the end, I found out that the fastest way of building stairs is first build a curve, and than extrude along the curve to build handrails and other supporting structures. This is by far the fastest way of building stairs.
&lt;br /&gt;&lt;br /&gt;&lt;/p&gt;

</description>
				
				<pubDate>Wed, 31 Jan 2018 00:00:00 -0800</pubDate>
				<link>http://localhost:4000/post/extrude-curve/</link>
				<guid isPermaLink="true">http://localhost:4000/post/extrude-curve/</guid>
			</item>
		
	</channel>
</rss>
