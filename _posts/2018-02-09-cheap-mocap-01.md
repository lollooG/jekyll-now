---
title: Cheapest Mocap Solution, Step 1
layout: post
type: image
homedisplay: featimg
author: lolloo
featimg: mocap_step_01/overview.png
comments: true
tags:
- script
- maya
- motion capture
category:
- script
- featuring
---

# Overview
<br/><br/>
There are a lot of motion capture options on the markets right now, but for individual hobby level motion capture, the choice is limited. For example there are Kinect, PS move, OptiTrack... But all of these options will involve another 3 party software to make them mocap capable, which is another few hundred dollars out of my pocket. 
<br/><br/>
In the end, after trying out few dozens different methods. The cheapest mocap solution is to use one single Kinect, ni-mate and write the rest of the code myself. So for step one, I included the the ni-mate and Kinect setup and export the mocap result into maya.
<br/><br/><br/>
# the test
<br/><br/>
To optimize the result, I uses a home made LED rig to light myself up as bright as possible. Open ni-mate and start adjusting it. The result is promising. There are some accuracy issue, for example, the hip and chest following is not as responsive as I like it to be. Also the system have a hard time detecting rotation. But all of these are hardware issues that came with using Kinect. The bottle neck of using this method is Kinect and not the software. But at hobby level, this is best result I can hope for.
<br/><br/>
So the next step is to export the mocap skeleton, which can be done by ni-mate maya plug-in.
<br/><br/>
{% include webm_player.html param="img/mocap_step_01/setp_01.webm" %}
<br/><br/><br/>
# Challenges
<br/><br/>
Here I ran into some problem, before I got it working. Ni-mate have a issue of exporting to many data to maya, which is not explained in the official document. What happened is the whole pipeline will froze and stop transferring any mocap data into maya. 
<br/><br/>
The solution is a little underwhelming, I just excluded my fingersâ€™ mocap data, since it is non-usable anyway. And to my surprise, everything turned out OK after that, I was comfortability recording mocap data in Maya.
<br/><br/><br/>
# Next Step
<br/><br/>
Here is where the hard-work starts, the mocap data right now are raw rotation and translation in the form a locater. To use these data, I need to write the script to build a skeleton to fit the mocap data. And  another script to transfer movement into my own animation.